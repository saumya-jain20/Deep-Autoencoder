{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **Botnet Detection in IOT devices using an Autoencoder**"
      ],
      "metadata": {
        "id": "9-ruSmzdV389"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loading Required Libraries"
      ],
      "metadata": {
        "id": "yrXgsrKlaPu8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dto_7VkVG0a"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras import layers, losses, Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Mounting drive"
      ],
      "metadata": {
        "id": "teSgS1sXWEv0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/drive')"
      ],
      "metadata": {
        "id": "7kiuEU97VmLQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a46a2d51-bd06-4209-8921-ad8ca31b1be3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /drive; to attempt to forcibly remount, call drive.mount(\"/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Autoencoder"
      ],
      "metadata": {
        "id": "1t6gWn6Jd0k8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "class Autoencoder(Model):\n",
        "    def __init__(self):\n",
        "        super(Autoencoder, self).__init__()\n",
        "        self.encoder = Sequential([\n",
        "            layers.Dense(115, activation=\"relu\"),\n",
        "            layers.Dense(86, activation=\"relu\"),\n",
        "            layers.Dense(57, activation=\"relu\"),\n",
        "            layers.Dense(37, activation=\"relu\"),\n",
        "            layers.Dense(28, activation=\"relu\")\n",
        "        ])\n",
        "        self.decoder = Sequential([\n",
        "            layers.Dense(37, activation=\"relu\"),\n",
        "            layers.Dense(57, activation=\"relu\"),\n",
        "            layers.Dense(86, activation=\"relu\"),\n",
        "            layers.Dense(115, activation=\"sigmoid\")\n",
        "        ])\n",
        "    \n",
        "    def call(self, x):\n",
        "        encoded = self.encoder(x)\n",
        "        decoded = self.decoder(encoded)\n",
        "        return decoded"
      ],
      "metadata": {
        "id": "Oc2GYrxXd4be"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function To print Stats"
      ],
      "metadata": {
        "id": "13l1yF66eEd8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def print_stats(data, outcome):\n",
        "    print(f\"Shape of data: {data.shape}\")\n",
        "    print(f\"Detected anomalies: {np.mean(outcome)*100}%\")\n",
        "    print()"
      ],
      "metadata": {
        "id": "EAkjJbFReI_t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 1: Danmini Doorbell"
      ],
      "metadata": {
        "id": "-7NC0uniadRt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "U8z6Sq9QX-ET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"1.benign.csv\")\n",
        "X_train = benign[:30000]\n",
        "X_train0 = benign[30000:40000]\n",
        "X_train1 = benign[30000:]\n",
        "X_test0 = benign[40000:]\n",
        "X_test1 = load_nbaiot(\"1.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"1.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"1.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"1.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"1.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"1.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"1.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"1.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"1.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"1.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "-SK9Z9TKYLG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "id": "FUmUVBiaYg3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa669a45-eb29-49fe-b130-b0dd544be481"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 115) (10000, 115) (19548, 115) (9548, 115) (107685, 115) (102195, 115) (122573, 115) (237665, 115) (81982, 115) (59718, 115) (29068, 115) (29849, 115) (92141, 115) (105874, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "CY-RXxMSeXtb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae1_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "id": "Gpn992UJecO0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c45cfa5-9650-47dd-da57-5a677ebcd564"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "649/657 [============================>.] - ETA: 0s - loss: 0.0033\n",
            "Epoch 1: val_loss improved from -inf to 0.00052, saving model to ae1_model\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.0032 - val_loss: 5.2203e-04\n",
            "Epoch 2/800\n",
            "653/657 [============================>.] - ETA: 0s - loss: 8.1512e-04\n",
            "Epoch 2: val_loss did not improve from 0.00052\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 8.1555e-04 - val_loss: 4.1606e-04\n",
            "Epoch 3/800\n",
            "654/657 [============================>.] - ETA: 0s - loss: 9.0165e-04\n",
            "Epoch 3: val_loss did not improve from 0.00052\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 8.9929e-04 - val_loss: 4.5692e-04\n",
            "Epoch 4/800\n",
            "654/657 [============================>.] - ETA: 0s - loss: 7.7013e-04\n",
            "Epoch 4: val_loss improved from 0.00052 to 0.00056, saving model to ae1_model\n",
            "657/657 [==============================] - 6s 10ms/step - loss: 7.7082e-04 - val_loss: 5.5799e-04\n",
            "Epoch 5/800\n",
            "657/657 [==============================] - ETA: 0s - loss: 8.6045e-04\n",
            "Epoch 5: val_loss did not improve from 0.00056\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 8.6045e-04 - val_loss: 4.4858e-04\n",
            "Epoch 6/800\n",
            "650/657 [============================>.] - ETA: 0s - loss: 0.0010\n",
            "Epoch 6: val_loss improved from 0.00056 to 0.00068, saving model to ae1_model\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 0.0010 - val_loss: 6.7559e-04\n",
            "Epoch 7/800\n",
            "651/657 [============================>.] - ETA: 0s - loss: 7.7660e-04\n",
            "Epoch 7: val_loss did not improve from 0.00068\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 7.7456e-04 - val_loss: 3.9136e-04\n",
            "Epoch 8/800\n",
            "646/657 [============================>.] - ETA: 0s - loss: 7.7179e-04\n",
            "Epoch 8: val_loss did not improve from 0.00068\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 7.7852e-04 - val_loss: 5.2560e-04\n",
            "Epoch 9/800\n",
            "651/657 [============================>.] - ETA: 0s - loss: 8.0197e-04\n",
            "Epoch 9: val_loss improved from 0.00068 to 0.00091, saving model to ae1_model\n",
            "657/657 [==============================] - 5s 8ms/step - loss: 8.0711e-04 - val_loss: 9.0576e-04\n",
            "Epoch 10/800\n",
            "656/657 [============================>.] - ETA: 0s - loss: 7.2488e-04\n",
            "Epoch 10: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 7.2489e-04 - val_loss: 7.2401e-04\n",
            "Epoch 11/800\n",
            "647/657 [============================>.] - ETA: 0s - loss: 7.0266e-04\n",
            "Epoch 11: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 7.0251e-04 - val_loss: 3.4140e-04\n",
            "Epoch 12/800\n",
            "650/657 [============================>.] - ETA: 0s - loss: 5.8532e-04\n",
            "Epoch 12: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 5.9262e-04 - val_loss: 4.5757e-04\n",
            "Epoch 13/800\n",
            "653/657 [============================>.] - ETA: 0s - loss: 5.5028e-04\n",
            "Epoch 13: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 5.4910e-04 - val_loss: 3.2663e-04\n",
            "Epoch 14/800\n",
            "651/657 [============================>.] - ETA: 0s - loss: 5.3628e-04\n",
            "Epoch 14: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 5.3652e-04 - val_loss: 2.9149e-04\n",
            "Epoch 15/800\n",
            "656/657 [============================>.] - ETA: 0s - loss: 8.0005e-04\n",
            "Epoch 15: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 7.9984e-04 - val_loss: 6.4913e-04\n",
            "Epoch 16/800\n",
            "653/657 [============================>.] - ETA: 0s - loss: 6.5018e-04\n",
            "Epoch 16: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 6.4833e-04 - val_loss: 4.0895e-04\n",
            "Epoch 17/800\n",
            "652/657 [============================>.] - ETA: 0s - loss: 6.3482e-04\n",
            "Epoch 17: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 6.3209e-04 - val_loss: 3.4182e-04\n",
            "Epoch 18/800\n",
            "651/657 [============================>.] - ETA: 0s - loss: 5.7645e-04\n",
            "Epoch 18: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 5.8019e-04 - val_loss: 3.6190e-04\n",
            "Epoch 19/800\n",
            "646/657 [============================>.] - ETA: 0s - loss: 6.8443e-04\n",
            "Epoch 19: val_loss did not improve from 0.00091\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 6.8213e-04 - val_loss: 4.2211e-04\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87DP5slwU_zd",
        "outputId": "099c54cf-f10c-4970-ea0a-4e86c16821a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 5ms/step - loss: 0.0362 - val_loss: 0.0328\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0345 - val_loss: 0.0328\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0345 - val_loss: 0.0328\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0345 - val_loss: 0.0328\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0345 - val_loss: 0.0328\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0345 - val_loss: 0.0328\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae1_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1llccgOVAQG",
        "outputId": "4014cd80-dfeb-44f9-9233-7834268a2d23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.0014 - val_loss: 4.3470e-04\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 3.8897e-04\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 3.8393e-04\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 4.7312e-04\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 3.9741e-04\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 3.8330e-04\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 8.5451e-04\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.0798e-04\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 3.8572e-04\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.1426e-04\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 5.2247e-04\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "TruJkLt9_GhW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vFD2wMbt_LIO",
        "outputId": "9d54d345-1dd1-4fb6-fa95-e500f16b08f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (9548, 115)\n",
            "Detected anomalies: 0.285201225308968%\n",
            "\n",
            "1\n",
            "Shape of data: (107685, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (102195, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (122573, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (237665, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (81982, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (59718, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (29068, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (29849, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (92141, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (105874, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae1_model')\n",
        "\n",
        "def predict(x, threshold=0.006098755, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "id": "Riy8bNUKYuwq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6c9817e-a839-4108-e065-fcee0d36d208"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (19548, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "1\n",
            "Shape of data: (107685, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (102195, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (122573, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (237665, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (81982, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (59718, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (29068, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (29849, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (92141, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (105874, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "id": "ttBp6gK1Zb0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc38f773-cfdd-417d-9832-01f8d794f3b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (9548, 115)\n",
            "Detected anomalies: 0.5387134255836062%\n",
            "\n",
            "1\n",
            "Shape of data: (107685, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (102195, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (122573, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (237665, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (81982, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (59718, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (29068, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (29849, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (92141, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (105874, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 2: Ecobee Thermostat\n"
      ],
      "metadata": {
        "id": "-1vXUijAnHvJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "TNcg-PkqnHvK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"2.benign.csv\")\n",
        "X_train = benign[:5000]\n",
        "X_train0 = benign[5000:10000]\n",
        "X_train1 = benign[5000:]\n",
        "X_test0 = benign[10000:]\n",
        "X_test1 = load_nbaiot(\"2.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"2.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"2.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"2.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"2.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"2.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"2.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"2.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"2.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"2.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "qT4DmajtnHvK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0547aac9-9131-4420-b449-5204b9b1c593",
        "id": "a85OmTqmnHvL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5000, 115) (5000, 115) (8113, 115) (3113, 115) (43192, 115) (113285, 115) (116807, 115) (151481, 115) (87368, 115) (53012, 115) (30312, 115) (27494, 115) (95021, 115) (104791, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "Kv5MZWEOnHvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae2_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "57142702-1f69-4484-c060-ca327c7a3b83",
        "id": "j7NBGJYgnHvM"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            " 99/110 [==========================>...] - ETA: 0s - loss: 0.0128\n",
            "Epoch 1: val_loss improved from -inf to 0.00360, saving model to ae2_model\n",
            "110/110 [==============================] - 10s 90ms/step - loss: 0.0121 - val_loss: 0.0036\n",
            "Epoch 2/800\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.0040\n",
            "Epoch 2: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0025\n",
            "Epoch 3/800\n",
            "100/110 [==========================>...] - ETA: 0s - loss: 0.0032\n",
            "Epoch 3: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0020\n",
            "Epoch 4/800\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.0028\n",
            "Epoch 4: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 5/800\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.0025\n",
            "Epoch 5: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0018\n",
            "Epoch 6/800\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.0023\n",
            "Epoch 6: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0016\n",
            "Epoch 7/800\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.0024\n",
            "Epoch 7: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0024 - val_loss: 0.0016\n",
            "Epoch 8/800\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.0025\n",
            "Epoch 8: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0015\n",
            "Epoch 9/800\n",
            "109/110 [============================>.] - ETA: 0s - loss: 0.0025\n",
            "Epoch 9: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0015\n",
            "Epoch 10/800\n",
            "105/110 [===========================>..] - ETA: 0s - loss: 0.0023\n",
            "Epoch 10: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0019\n",
            "Epoch 11/800\n",
            "103/110 [===========================>..] - ETA: 0s - loss: 0.0019\n",
            "Epoch 11: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 0.0015\n",
            "Epoch 12/800\n",
            "106/110 [===========================>..] - ETA: 0s - loss: 0.0025\n",
            "Epoch 12: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 13/800\n",
            "100/110 [==========================>...] - ETA: 0s - loss: 0.0027\n",
            "Epoch 13: val_loss did not improve from 0.00360\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0027 - val_loss: 0.0019\n",
            "Epoch 13: early stopping\n",
            "0.008497585\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8646413c-9cc1-4799-f1c5-6f1d2211c6a7",
        "id": "MhZZUc12nHvN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0147 - val_loss: 0.0044\n",
            "Epoch 2/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0042 - val_loss: 0.0024\n",
            "Epoch 3/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0022\n",
            "Epoch 4/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0024\n",
            "Epoch 5/800\n",
            "110/110 [==============================] - 0s 5ms/step - loss: 0.0035 - val_loss: 0.0022\n",
            "Epoch 6/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 7/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 8/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0022\n",
            "Epoch 9/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 10/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0024 - val_loss: 0.0015\n",
            "Epoch 11/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 12/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.0015\n",
            "Epoch 13/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 0.0014\n",
            "Epoch 14/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0015\n",
            "Epoch 15/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 0.0015\n",
            "Epoch 16/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 17/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0011\n",
            "Epoch 18/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 0.0010\n",
            "Epoch 19/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 20/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0014\n",
            "Epoch 21/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 0.0020\n",
            "Epoch 22/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0019\n",
            "Epoch 23/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.0012\n",
            "Epoch 23: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae2_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9eb78ba0-e358-467f-fb1f-b0bf82ae28e8",
        "id": "a_z4foGFnHvN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "110/110 [==============================] - 1s 7ms/step - loss: 0.0050 - val_loss: 0.0030\n",
            "Epoch 2/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0024\n",
            "Epoch 3/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 0.0065\n",
            "Epoch 4/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0044 - val_loss: 0.0027\n",
            "Epoch 5/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 6/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0020\n",
            "Epoch 7/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 0.0023\n",
            "Epoch 8/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0028 - val_loss: 0.0019\n",
            "Epoch 9/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0018\n",
            "Epoch 10/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0026 - val_loss: 0.0021\n",
            "Epoch 11/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0028 - val_loss: 0.0017\n",
            "Epoch 12/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0030 - val_loss: 0.0019\n",
            "Epoch 13/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0025 - val_loss: 0.0017\n",
            "Epoch 14/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0024\n",
            "Epoch 15/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.0039\n",
            "Epoch 16/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0041 - val_loss: 0.0032\n",
            "Epoch 17/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0033 - val_loss: 0.0025\n",
            "Epoch 18/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0032 - val_loss: 0.0043\n",
            "Epoch 18: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "NLr_vsgSnHvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd40f67c-e5d2-40da-f9ae-b757b9dc6070",
        "id": "4zh-XaqonHvO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (3113, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "1\n",
            "Shape of data: (43192, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (113285, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (116807, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (151481, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (87368, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (53012, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (30312, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27494, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (95021, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104791, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae2_model')\n",
        "\n",
        "def predict(x, threshold=0.008497585, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d2fd9c3-0eb8-4d8e-8ab7-b9562c5c3c9a",
        "id": "uC8DvkdlnHvO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (8113, 115)\n",
            "Detected anomalies: 1.9173306772908367%\n",
            "\n",
            "1\n",
            "Shape of data: (43192, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (113285, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (116807, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (151481, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (87368, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (53012, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (30312, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27494, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (95021, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104791, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "89f39d98-bb6c-4209-816b-6348f8407c35",
        "id": "k17qsLkXnHvP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (3113, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "1\n",
            "Shape of data: (43192, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (113285, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (116807, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (151481, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (87368, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (53012, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (30312, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27494, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (95021, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104791, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 3: Ennio Doorbell"
      ],
      "metadata": {
        "id": "UiEpriETr7iT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "JLJ1QzZkr7iV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"3.benign.csv\")\n",
        "X_train = benign[:30000]\n",
        "X_train0 = benign[30000:35000]\n",
        "X_train1 = benign[30000:]\n",
        "X_test0 = benign[35000:]\n",
        "X_test6 = load_nbaiot(\"3.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"3.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"3.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"3.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"3.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "POWsT7okr7iV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96302457-162b-4e0f-97fc-e9a23654febd",
        "id": "iULWTWkgr7iV"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 115) (5000, 115) (9100, 115) (4100, 115) (53014, 115) (29797, 115) (28120, 115) (101536, 115) (103933, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "f7A2UO-fr7iW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae3_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "476355fd-36a2-45ae-fec8-48d9c9e33887",
        "id": "LNg6OTR9r7iW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "652/657 [============================>.] - ETA: 0s - loss: 0.0543\n",
            "Epoch 1: val_loss improved from -inf to 0.04177, saving model to ae3_model\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.0543 - val_loss: 0.0418\n",
            "Epoch 2/800\n",
            "647/657 [============================>.] - ETA: 0s - loss: 0.0540\n",
            "Epoch 2: val_loss did not improve from 0.04177\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0539 - val_loss: 0.0418\n",
            "Epoch 3/800\n",
            "646/657 [============================>.] - ETA: 0s - loss: 0.0539\n",
            "Epoch 3: val_loss did not improve from 0.04177\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0539 - val_loss: 0.0418\n",
            "Epoch 4/800\n",
            "645/657 [============================>.] - ETA: 0s - loss: 0.0540\n",
            "Epoch 4: val_loss did not improve from 0.04177\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0539 - val_loss: 0.0418\n",
            "Epoch 5/800\n",
            "657/657 [==============================] - ETA: 0s - loss: 0.0549\n",
            "Epoch 5: val_loss improved from 0.04177 to 0.04710, saving model to ae3_model\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.0549 - val_loss: 0.0471\n",
            "Epoch 6/800\n",
            "653/657 [============================>.] - ETA: 0s - loss: 0.0581\n",
            "Epoch 6: val_loss did not improve from 0.04710\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0581 - val_loss: 0.0471\n",
            "Epoch 6: early stopping\n",
            "0.08886978\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "13ddda52-01b0-41e9-d3fe-c780cb595291",
        "id": "9yaE9n8Ur7iW"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0146 - val_loss: 0.0113\n",
            "Epoch 2/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0050 - val_loss: 0.0079\n",
            "Epoch 3/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0030 - val_loss: 0.0069\n",
            "Epoch 4/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 0.0065\n",
            "Epoch 5/800\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.0021 - val_loss: 0.0054\n",
            "Epoch 6/800\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0024 - val_loss: 0.0067\n",
            "Epoch 7/800\n",
            "110/110 [==============================] - 1s 9ms/step - loss: 0.0016 - val_loss: 0.0047\n",
            "Epoch 8/800\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.0014 - val_loss: 0.0045\n",
            "Epoch 9/800\n",
            "110/110 [==============================] - 1s 8ms/step - loss: 0.0013 - val_loss: 0.0047\n",
            "Epoch 10/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0033 - val_loss: 0.0084\n",
            "Epoch 11/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0088\n",
            "Epoch 12/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0033 - val_loss: 0.0109\n",
            "Epoch 13/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0038 - val_loss: 0.0139\n",
            "Epoch 13: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae3_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6675e140-05a3-4785-dfef-0616bc209cb9",
        "id": "FU3v6egGr7iX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0731 - val_loss: 0.0442\n",
            "Epoch 2/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0081 - val_loss: 0.0117\n",
            "Epoch 3/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0040 - val_loss: 0.0082\n",
            "Epoch 4/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0036 - val_loss: 0.0110\n",
            "Epoch 5/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0037 - val_loss: 0.0074\n",
            "Epoch 6/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0027 - val_loss: 0.0093\n",
            "Epoch 7/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0076\n",
            "Epoch 8/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0025 - val_loss: 0.0064\n",
            "Epoch 9/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0063\n",
            "Epoch 10/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0052\n",
            "Epoch 11/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0049\n",
            "Epoch 12/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 0.0047\n",
            "Epoch 13/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0047\n",
            "Epoch 14/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0042\n",
            "Epoch 15/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0044\n",
            "Epoch 16/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0084\n",
            "Epoch 17/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0036 - val_loss: 0.0076\n",
            "Epoch 18/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0024 - val_loss: 0.0096\n",
            "Epoch 19/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0075 - val_loss: 0.0096\n",
            "Epoch 19: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "ry8qxbQsr7iX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "030596aa-b069-4551-b5d6-f3ff27723f95",
        "id": "iOic9fgir7iX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (4100, 115)\n",
            "Detected anomalies: 4.4787260512565314%\n",
            "\n",
            "1\n",
            "Shape of data: (53014, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (29797, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (28120, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (101536, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (103933, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae3_model')\n",
        "\n",
        "def predict(x, threshold=0.08886978, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ff9ac0c-d5e2-49a2-9656-ffa41a0711a0",
        "id": "nwcT3pg_r7iX"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (9100, 115)\n",
            "Detected anomalies: 2.2618915622574565%\n",
            "\n",
            "1\n",
            "Shape of data: (53014, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (29797, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (28120, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (101536, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (103933, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d0bc26c-e641-4169-f8b8-5b1f5aefb4f0",
        "id": "XQJ7Fry0r7iY"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (4100, 115)\n",
            "Detected anomalies: 4.677780542423489%\n",
            "\n",
            "1\n",
            "Shape of data: (53014, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (29797, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (28120, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (101536, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (103933, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 4: Philips B120N10 Baby Monitor"
      ],
      "metadata": {
        "id": "tOh62_PA5hhk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "DL3ouEvE5hhs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"4.benign.csv\")\n",
        "X_train = benign[:150000]\n",
        "X_train0 = benign[150000:170000]\n",
        "X_train1 = benign[150000:]\n",
        "X_test0 = benign[170000:]\n",
        "X_test1 = load_nbaiot(\"4.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"4.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"4.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"4.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"4.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"4.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"4.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"4.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"4.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"4.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "ZuSlqUYi5hhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97596ae9-a74d-4725-c20d-6f96f417957b",
        "id": "zJWYRsuB5hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(150000, 115) (20000, 115) (25240, 115) (5240, 115) (103621, 115) (91123, 115) (118128, 115) (217034, 115) (80808, 115) (58152, 115) (28349, 115) (27859, 115) (92581, 115) (105782, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "XVE4Nx_z5hht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae4_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce08e7e4-01d1-426b-9dc8-dd38579afa2e",
        "id": "vcyUZmGb5hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "3278/3282 [============================>.] - ETA: 0s - loss: 0.0030\n",
            "Epoch 1: val_loss improved from -inf to 0.04721, saving model to ae4_model\n",
            "3282/3282 [==============================] - 24s 7ms/step - loss: 0.0031 - val_loss: 0.0472\n",
            "Epoch 2/800\n",
            "3278/3282 [============================>.] - ETA: 0s - loss: 0.0507\n",
            "Epoch 2: val_loss improved from 0.04721 to 0.04906, saving model to ae4_model\n",
            "3282/3282 [==============================] - 19s 6ms/step - loss: 0.0507 - val_loss: 0.0491\n",
            "Epoch 3/800\n",
            "3273/3282 [============================>.] - ETA: 0s - loss: 0.0508\n",
            "Epoch 3: val_loss did not improve from 0.04906\n",
            "3282/3282 [==============================] - 16s 5ms/step - loss: 0.0508 - val_loss: 0.0491\n",
            "Epoch 4/800\n",
            "3277/3282 [============================>.] - ETA: 0s - loss: 0.0508\n",
            "Epoch 4: val_loss did not improve from 0.04906\n",
            "3282/3282 [==============================] - 16s 5ms/step - loss: 0.0508 - val_loss: 0.0491\n",
            "Epoch 5/800\n",
            "3276/3282 [============================>.] - ETA: 0s - loss: 0.0508\n",
            "Epoch 5: val_loss did not improve from 0.04906\n",
            "3282/3282 [==============================] - 16s 5ms/step - loss: 0.0508 - val_loss: 0.0491\n",
            "Epoch 6/800\n",
            "3280/3282 [============================>.] - ETA: 0s - loss: 0.0508\n",
            "Epoch 6: val_loss did not improve from 0.04906\n",
            "3282/3282 [==============================] - 17s 5ms/step - loss: 0.0508 - val_loss: 0.0491\n",
            "Epoch 6: early stopping\n",
            "0.082419306\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fabfe8de-3cde-43a9-9aa5-b1e94075e746",
        "id": "MPhytSM45hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "438/438 [==============================] - 4s 6ms/step - loss: 0.0034 - val_loss: 0.0040\n",
            "Epoch 2/800\n",
            "438/438 [==============================] - 3s 7ms/step - loss: 7.9645e-04 - val_loss: 0.0052\n",
            "Epoch 3/800\n",
            "438/438 [==============================] - 3s 6ms/step - loss: 8.1644e-04 - val_loss: 0.0062\n",
            "Epoch 4/800\n",
            "438/438 [==============================] - 4s 9ms/step - loss: 0.0012 - val_loss: 0.0040\n",
            "Epoch 5/800\n",
            "438/438 [==============================] - 3s 7ms/step - loss: 6.5935e-04 - val_loss: 0.0040\n",
            "Epoch 6/800\n",
            "438/438 [==============================] - 2s 5ms/step - loss: 6.7478e-04 - val_loss: 0.0042\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae4_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af904df9-0ccb-41fc-e7e5-18459fa151fa",
        "id": "fuEYZkEI5hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "438/438 [==============================] - 3s 5ms/step - loss: 0.0807 - val_loss: 0.0851\n",
            "Epoch 2/800\n",
            "438/438 [==============================] - 2s 5ms/step - loss: 0.0807 - val_loss: 0.0851\n",
            "Epoch 3/800\n",
            "438/438 [==============================] - 2s 5ms/step - loss: 0.0807 - val_loss: 0.0851\n",
            "Epoch 4/800\n",
            "438/438 [==============================] - 2s 5ms/step - loss: 0.0807 - val_loss: 0.0851\n",
            "Epoch 5/800\n",
            "438/438 [==============================] - 2s 5ms/step - loss: 0.0807 - val_loss: 0.0851\n",
            "Epoch 6/800\n",
            "438/438 [==============================] - 2s 5ms/step - loss: 0.0807 - val_loss: 0.0851\n",
            "Epoch 6: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "FYUoRcm65hht"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b223ab2d-95cc-4d1c-af66-dadb574346e6",
        "id": "mBNisgrq5hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (5240, 115)\n",
            "Detected anomalies: 19.073463849583252%\n",
            "\n",
            "1\n",
            "Shape of data: (103621, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (91123, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (118128, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (217034, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (80808, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (58152, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (28349, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27859, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (92581, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (105782, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae4_model')\n",
        "\n",
        "def predict(x, threshold=0.082419306, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f011942f-5c16-4240-a95e-d3c8b0ac914d",
        "id": "Zy9Ymy2R5hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (25240, 115)\n",
            "Detected anomalies: 10.576731984578084%\n",
            "\n",
            "1\n",
            "Shape of data: (103621, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (91123, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (118128, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (217034, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (80808, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (58152, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (28349, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27859, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (92581, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (105782, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6101316-421e-41a0-b5de-a148b8d3c0a6",
        "id": "kRWO32UT5hht"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (5240, 115)\n",
            "Detected anomalies: 16.747431672804808%\n",
            "\n",
            "1\n",
            "Shape of data: (103621, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (91123, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (118128, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (217034, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (80808, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (58152, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (28349, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27859, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (92581, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (105782, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 5: Provision PT 737E Security Camera"
      ],
      "metadata": {
        "id": "dK5xKmLs_S6U"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "__Pd8ABQ_S6V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"5.benign.csv\")\n",
        "X_train = benign[:50000]\n",
        "X_train0 = benign[50000:60000]\n",
        "X_train1 = benign[50000:]\n",
        "X_test0 = benign[60000:]\n",
        "X_test1 = load_nbaiot(\"5.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"5.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"5.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"5.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"5.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"5.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"5.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"5.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"5.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"5.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "TrbDEM8r_S6V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f697a1e-5c0f-4d6b-83f1-a9618352c748",
        "id": "dODldguS_S6V"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 115) (10000, 115) (12154, 115) (2154, 115) (96781, 115) (60554, 115) (65746, 115) (156248, 115) (56681, 115) (61380, 115) (30898, 115) (29297, 115) (104510, 115) (104011, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "RG92DVXB_S6W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae5_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b68a3457-be2f-422b-eb9d-19ff02461cf6",
        "id": "QOI7RCTs_S6W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "1091/1094 [============================>.] - ETA: 0s - loss: 0.0037\n",
            "Epoch 1: val_loss improved from -inf to 0.00121, saving model to ae5_model\n",
            "1094/1094 [==============================] - 10s 9ms/step - loss: 0.0037 - val_loss: 0.0012\n",
            "Epoch 2/800\n",
            "1091/1094 [============================>.] - ETA: 0s - loss: 0.0018\n",
            "Epoch 2: val_loss improved from 0.00121 to 0.00234, saving model to ae5_model\n",
            "1094/1094 [==============================] - 11s 10ms/step - loss: 0.0018 - val_loss: 0.0023\n",
            "Epoch 3/800\n",
            "1089/1094 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 3: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 5s 5ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 4/800\n",
            "1091/1094 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 4: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 5s 5ms/step - loss: 0.0013 - val_loss: 0.0010\n",
            "Epoch 5/800\n",
            "1091/1094 [============================>.] - ETA: 0s - loss: 9.0732e-04\n",
            "Epoch 5: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 9.0730e-04 - val_loss: 0.0010\n",
            "Epoch 6/800\n",
            "1088/1094 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 6: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 5s 5ms/step - loss: 0.0012 - val_loss: 9.7283e-04\n",
            "Epoch 7/800\n",
            "1090/1094 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 7: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.0011 - val_loss: 0.0011\n",
            "Epoch 8/800\n",
            "1090/1094 [============================>.] - ETA: 0s - loss: 9.5532e-04\n",
            "Epoch 8: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 9.5538e-04 - val_loss: 9.0832e-04\n",
            "Epoch 9/800\n",
            "1084/1094 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 9: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 10/800\n",
            "1087/1094 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 10: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 11/800\n",
            "1092/1094 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 11: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0013 - val_loss: 9.7695e-04\n",
            "Epoch 12/800\n",
            "1083/1094 [============================>.] - ETA: 0s - loss: 8.3531e-04\n",
            "Epoch 12: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 8s 8ms/step - loss: 8.3428e-04 - val_loss: 8.0878e-04\n",
            "Epoch 13/800\n",
            "1089/1094 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 13: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 0.0012 - val_loss: 9.5857e-04\n",
            "Epoch 14/800\n",
            "1085/1094 [============================>.] - ETA: 0s - loss: 9.6408e-04\n",
            "Epoch 14: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 9.6480e-04 - val_loss: 0.0011\n",
            "Epoch 15/800\n",
            "1092/1094 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 15: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 0.0012 - val_loss: 9.9050e-04\n",
            "Epoch 16/800\n",
            "1090/1094 [============================>.] - ETA: 0s - loss: 8.9007e-04\n",
            "Epoch 16: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 6ms/step - loss: 8.8976e-04 - val_loss: 8.8078e-04\n",
            "Epoch 17/800\n",
            "1084/1094 [============================>.] - ETA: 0s - loss: 9.4333e-04\n",
            "Epoch 17: val_loss did not improve from 0.00234\n",
            "1094/1094 [==============================] - 6s 5ms/step - loss: 9.4563e-04 - val_loss: 0.0011\n",
            "Epoch 17: early stopping\n",
            "0.0044242707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e37075b-f3ea-47ab-8dae-285658f885f1",
        "id": "0d99t5X-_S6W"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.0119 - val_loss: 0.0068\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0035 - val_loss: 0.0026\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0032\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0028\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 0.0010\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 8.7793e-04 - val_loss: 9.9605e-04\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0012\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 8.3418e-04 - val_loss: 9.4676e-04\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 0.0025\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 8.1844e-04 - val_loss: 8.5801e-04\n",
            "Epoch 12/800\n",
            "219/219 [==============================] - 1s 7ms/step - loss: 7.0335e-04 - val_loss: 9.9129e-04\n",
            "Epoch 13/800\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 6.5136e-04 - val_loss: 8.0094e-04\n",
            "Epoch 14/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 5.9161e-04 - val_loss: 9.1861e-04\n",
            "Epoch 15/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 7.1820e-04 - val_loss: 0.0010\n",
            "Epoch 16/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 9.7632e-04 - val_loss: 0.0013\n",
            "Epoch 17/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 7.6363e-04 - val_loss: 7.9839e-04\n",
            "Epoch 18/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 7.4687e-04 - val_loss: 0.0010\n",
            "Epoch 19/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 5.7777e-04 - val_loss: 8.4321e-04\n",
            "Epoch 20/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 5.3220e-04 - val_loss: 8.1790e-04\n",
            "Epoch 21/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0038\n",
            "Epoch 22/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0023 - val_loss: 0.0018\n",
            "Epoch 22: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae5_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6732187-ca9c-47b8-c6b4-c6a866a33e91",
        "id": "mFZMFcv5_S6X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 3s 11ms/step - loss: 0.0026 - val_loss: 0.0016\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0014\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 0.0030\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0013\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.4122e-04 - val_loss: 0.0013\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.6046e-04 - val_loss: 0.0016\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.9306e-04 - val_loss: 0.0012\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 8.6106e-04 - val_loss: 0.0011\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 8.0712e-04 - val_loss: 0.0011\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0011 - val_loss: 0.0012\n",
            "Epoch 12/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0014\n",
            "Epoch 13/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0030 - val_loss: 0.0023\n",
            "Epoch 14/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0021 - val_loss: 0.0020\n",
            "Epoch 14: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "cXwa9Vu8_S6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80b66247-082d-44b8-d92b-6c237f19df0a",
        "id": "AKIWLVyH_S6X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (2154, 115)\n",
            "Detected anomalies: 11.577424023154848%\n",
            "\n",
            "1\n",
            "Shape of data: (96781, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (60554, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (65746, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (156248, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (56681, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (61380, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (30898, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (29297, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (104510, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104011, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae5_model')\n",
        "\n",
        "def predict(x, threshold=0.0044242707, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb5d8ea2-1bf6-4507-a46e-5ba282539d94",
        "id": "qhk9PNFX_S6X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (12154, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "1\n",
            "Shape of data: (96781, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (60554, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (65746, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (156248, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (56681, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (61380, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (30898, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (29297, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (104510, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104011, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb8e1a3-5e8a-497a-a6cf-76014ca88d17",
        "id": "N72atTOO_S6Y"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (2154, 115)\n",
            "Detected anomalies: 5.692233478051134%\n",
            "\n",
            "1\n",
            "Shape of data: (96781, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (60554, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (65746, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (156248, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (56681, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (61380, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (30898, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (29297, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (104510, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104011, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 6: Provision PT 838 Security Camera"
      ],
      "metadata": {
        "id": "k8i5OY3hE3ew"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "seNPbY_AE3e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"6.benign.csv\")\n",
        "X_train = benign[:80000]\n",
        "X_train0 = benign[80000:90000]\n",
        "X_train1 = benign[80000:]\n",
        "X_test0 = benign[90000:]\n",
        "X_test1 = load_nbaiot(\"6.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"6.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"6.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"6.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"6.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"6.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"6.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"6.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"6.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"6.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "_xT8IInIE3e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4bc720a-7b07-477b-8bbd-9498ce5b5253",
        "id": "lbwCW0QNE3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(80000, 115) (10000, 115) (18514, 115) (8514, 115) (97096, 115) (57997, 115) (61851, 115) (158608, 115) (53785, 115) (57530, 115) (29068, 115) (28397, 115) (89387, 115) (104658, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "1KxdBsfcE3e5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae6_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bab3f2d-30c3-4f60-9152-8e6175f2893a",
        "id": "z5FZZLT8E3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "1742/1750 [============================>.] - ETA: 0s - loss: 0.0034\n",
            "Epoch 1: val_loss improved from -inf to 0.00162, saving model to ae6_model\n",
            "1750/1750 [==============================] - 17s 10ms/step - loss: 0.0034 - val_loss: 0.0016\n",
            "Epoch 2/800\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 2: val_loss did not improve from 0.00162\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0013 - val_loss: 0.0016\n",
            "Epoch 3/800\n",
            "1746/1750 [============================>.] - ETA: 0s - loss: 0.0015\n",
            "Epoch 3: val_loss improved from 0.00162 to 0.00320, saving model to ae6_model\n",
            "1750/1750 [==============================] - 11s 6ms/step - loss: 0.0015 - val_loss: 0.0032\n",
            "Epoch 4/800\n",
            "1749/1750 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 4: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 0.0015\n",
            "Epoch 5/800\n",
            "1742/1750 [============================>.] - ETA: 0s - loss: 0.0019\n",
            "Epoch 5: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 10s 6ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 6/800\n",
            "1748/1750 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 6: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 0.0013\n",
            "Epoch 7/800\n",
            "1741/1750 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 7: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 0.0014\n",
            "Epoch 8/800\n",
            "1746/1750 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 8: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0012 - val_loss: 0.0013\n",
            "Epoch 9/800\n",
            "1744/1750 [============================>.] - ETA: 0s - loss: 0.0016\n",
            "Epoch 9: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 10/800\n",
            "1745/1750 [============================>.] - ETA: 0s - loss: 0.0016\n",
            "Epoch 10: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0016 - val_loss: 0.0015\n",
            "Epoch 11/800\n",
            "1739/1750 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 11: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 12/800\n",
            "1746/1750 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 12: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 13/800\n",
            "1745/1750 [============================>.] - ETA: 0s - loss: 0.0019\n",
            "Epoch 13: val_loss did not improve from 0.00320\n",
            "1750/1750 [==============================] - 9s 5ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 13: early stopping\n",
            "0.006529484\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29391ed1-e37d-43a7-ace2-f8added77bd4",
        "id": "YN2HYsFcE3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.0118 - val_loss: 0.0046\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0038 - val_loss: 0.0064\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0035 - val_loss: 0.0060\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0032 - val_loss: 0.0027\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 0.0021\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 0.0055\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0039 - val_loss: 0.0030\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0026 - val_loss: 0.0034\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0039 - val_loss: 0.0028\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0025\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae6_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f682104e-cf95-4e46-e33a-44e28548798b",
        "id": "WZAJDDiOE3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.0040 - val_loss: 0.0025\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0020\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0017\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0020\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 0.0033\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0016\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 0.0038\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0031 - val_loss: 0.0025\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0019\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0017\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0016\n",
            "Epoch 12/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 0.0029\n",
            "Epoch 13/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0032 - val_loss: 0.0019\n",
            "Epoch 14/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0018\n",
            "Epoch 15/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 0.0019\n",
            "Epoch 16/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0017\n",
            "Epoch 16: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "VXZC6j82E3e6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4635f440-8da2-498c-bc89-83514883414b",
        "id": "jbocUrdNE3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (8514, 115)\n",
            "Detected anomalies: 19.791296098660027%\n",
            "\n",
            "1\n",
            "Shape of data: (97096, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (57997, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (61851, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (158608, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (53785, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (57530, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (29068, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (28397, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (89387, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104658, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae6_model')\n",
        "\n",
        "def predict(x, threshold=0.006529484, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4634ce5-dd64-4dce-c3a2-56bb367e2c6a",
        "id": "-ew_7yNiE3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (18514, 115)\n",
            "Detected anomalies: 59.31752834590137%\n",
            "\n",
            "1\n",
            "Shape of data: (97096, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (57997, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (61851, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (158608, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (53785, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (57530, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (29068, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (28397, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (89387, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104658, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ce48dfa-6b3b-4fe4-9324-7e3f130eaba0",
        "id": "DPM8mseaE3e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (8514, 115)\n",
            "Detected anomalies: 19.60156527926005%\n",
            "\n",
            "1\n",
            "Shape of data: (97096, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (57997, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (61851, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (158608, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (53785, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (57530, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (29068, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (28397, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (89387, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (104658, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 7: Samsung SNH 1011 N Webcam"
      ],
      "metadata": {
        "id": "NUuyoczwK5WQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "J7IJ5Vl-K5WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"7.benign.csv\")\n",
        "X_train = benign[:40000]\n",
        "X_train0 = benign[40000:50000]\n",
        "X_train1 = benign[40000:]\n",
        "X_test0 = benign[50000:]\n",
        "X_test6 = load_nbaiot(\"7.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"7.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"7.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"7.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"7.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "jYdhAB7wK5WZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0cc8e927-b3ae-46ce-cf00-04decf5cb042",
        "id": "rl_hSoD2K5WZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(40000, 115) (10000, 115) (12150, 115) (2150, 115) (58669, 115) (28305, 115) (27698, 115) (97783, 115) (110617, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "6UwTeS25K5WZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae7_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a627b098-0b4a-42b5-fda0-bd6362ad1b87",
        "id": "RVceBblKK5WZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "865/875 [============================>.] - ETA: 0s - loss: 0.0029\n",
            "Epoch 1: val_loss improved from -inf to 0.00216, saving model to ae7_model\n",
            "875/875 [==============================] - 8s 8ms/step - loss: 0.0028 - val_loss: 0.0022\n",
            "Epoch 2/800\n",
            "874/875 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 2: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.0014 - val_loss: 0.0020\n",
            "Epoch 3/800\n",
            "872/875 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 3: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 5s 6ms/step - loss: 0.0012 - val_loss: 0.0021\n",
            "Epoch 4/800\n",
            "865/875 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 4: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 6s 7ms/step - loss: 0.0011 - val_loss: 0.0019\n",
            "Epoch 5/800\n",
            "871/875 [============================>.] - ETA: 0s - loss: 9.8556e-04\n",
            "Epoch 5: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 9.8371e-04 - val_loss: 0.0019\n",
            "Epoch 6/800\n",
            "865/875 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 6: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.0013 - val_loss: 0.0017\n",
            "Epoch 7/800\n",
            "863/875 [============================>.] - ETA: 0s - loss: 8.7655e-04\n",
            "Epoch 7: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 8.7412e-04 - val_loss: 0.0017\n",
            "Epoch 8/800\n",
            "873/875 [============================>.] - ETA: 0s - loss: 8.2955e-04\n",
            "Epoch 8: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 8.2897e-04 - val_loss: 0.0020\n",
            "Epoch 9/800\n",
            "874/875 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 9: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.0013 - val_loss: 0.0018\n",
            "Epoch 10/800\n",
            "873/875 [============================>.] - ETA: 0s - loss: 9.6151e-04\n",
            "Epoch 10: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 7s 8ms/step - loss: 9.6534e-04 - val_loss: 0.0018\n",
            "Epoch 11/800\n",
            "873/875 [============================>.] - ETA: 0s - loss: 8.9746e-04\n",
            "Epoch 11: val_loss did not improve from 0.00216\n",
            "875/875 [==============================] - 9s 10ms/step - loss: 8.9662e-04 - val_loss: 0.0016\n",
            "Epoch 12/800\n",
            "874/875 [============================>.] - ETA: 0s - loss: 0.0032\n",
            "Epoch 12: val_loss improved from 0.00216 to 0.00424, saving model to ae7_model\n",
            "875/875 [==============================] - 6s 7ms/step - loss: 0.0032 - val_loss: 0.0042\n",
            "Epoch 13/800\n",
            "872/875 [============================>.] - ETA: 0s - loss: 0.0022\n",
            "Epoch 13: val_loss did not improve from 0.00424\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.0022 - val_loss: 0.0036\n",
            "Epoch 14/800\n",
            "866/875 [============================>.] - ETA: 0s - loss: 0.0018\n",
            "Epoch 14: val_loss did not improve from 0.00424\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.0018 - val_loss: 0.0032\n",
            "Epoch 15/800\n",
            "872/875 [============================>.] - ETA: 0s - loss: 0.0016\n",
            "Epoch 15: val_loss did not improve from 0.00424\n",
            "875/875 [==============================] - 5s 6ms/step - loss: 0.0016 - val_loss: 0.0029\n",
            "Epoch 16/800\n",
            "875/875 [==============================] - ETA: 0s - loss: 0.0015\n",
            "Epoch 16: val_loss did not improve from 0.00424\n",
            "875/875 [==============================] - 4s 5ms/step - loss: 0.0015 - val_loss: 0.0028\n",
            "Epoch 16: early stopping\n",
            "0.00954742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21a18ab4-0b68-4aea-a68f-7c3bc660fee7",
        "id": "KeW10VfdK5Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.0131 - val_loss: 0.0057\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 3s 12ms/step - loss: 0.0028 - val_loss: 0.0018\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0042 - val_loss: 0.0023\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0022 - val_loss: 0.0018\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 0.0013\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 9.4975e-04\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0025 - val_loss: 0.0039\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0045 - val_loss: 0.0015\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0011\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0016 - val_loss: 0.0019\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 9.6927e-04\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae7_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "af56b449-52bc-4b0d-c27e-290c9baf85b5",
        "id": "iZuWJBkkK5Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 7ms/step - loss: 0.0402 - val_loss: 0.0183\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0166 - val_loss: 0.0110\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0123 - val_loss: 0.0089\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0118 - val_loss: 0.0093\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0114 - val_loss: 0.0085\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0114 - val_loss: 0.0089\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0111 - val_loss: 0.0087\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0111 - val_loss: 0.0088\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0112 - val_loss: 0.0087\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0110 - val_loss: 0.0089\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "CBJ_xGbXK5Wa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9f1ceed-ee59-4a02-8b99-833ef58b01d4",
        "id": "A0XWswGXK5Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (2150, 115)\n",
            "Detected anomalies: 52.7791203479942%\n",
            "\n",
            "1\n",
            "Shape of data: (58669, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (28305, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (27698, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (97783, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (110617, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae7_model')\n",
        "\n",
        "def predict(x, threshold=0.00954742, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b608f066-dba3-4898-944a-e2b9994ea469",
        "id": "JFLAIrLRK5Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (12150, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "1\n",
            "Shape of data: (58669, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (28305, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (27698, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (97783, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (110617, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8927684d-2dfc-4c41-dbdc-043398902c83",
        "id": "H1QvNHySK5Wa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (2150, 115)\n",
            "Detected anomalies: 56.74238762687288%\n",
            "\n",
            "1\n",
            "Shape of data: (58669, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (28305, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (27698, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (97783, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (110617, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 8: SimpleHome XCS7 1002 WHT Security Camera"
      ],
      "metadata": {
        "id": "0Kj6DEmZy0kS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "12I1_1HFOWp-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"8.benign.csv\")\n",
        "X_train = benign[:30000]\n",
        "X_train0 = benign[30000:40000]\n",
        "X_train1 = benign[30000:]\n",
        "X_test0 = benign[40000:]\n",
        "X_test1 = load_nbaiot(\"8.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"8.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"8.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"8.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"8.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"8.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"8.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"8.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"8.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"8.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "vWwiUt_OOWp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff70b4cf-458b-45f5-95b2-f75ab7f06b0c",
        "id": "fpBQA5fZOWp-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30000, 115) (10000, 115) (16585, 115) (6585, 115) (45930, 115) (111480, 115) (125715, 115) (151879, 115) (78244, 115) (54283, 115) (28579, 115) (27825, 115) (88816, 115) (103720, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "1zE9Jx2VOWp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae8_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b270ffe-6962-40e8-cad0-6a34bd7e8254",
        "id": "qB1Gpc1wOWp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "656/657 [============================>.] - ETA: 0s - loss: 0.0057\n",
            "Epoch 1: val_loss improved from -inf to 0.00101, saving model to ae8_model\n",
            "657/657 [==============================] - 7s 9ms/step - loss: 0.0057 - val_loss: 0.0010\n",
            "Epoch 2/800\n",
            "656/657 [============================>.] - ETA: 0s - loss: 0.0034\n",
            "Epoch 2: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 8s 12ms/step - loss: 0.0034 - val_loss: 7.8445e-04\n",
            "Epoch 3/800\n",
            "654/657 [============================>.] - ETA: 0s - loss: 0.0018\n",
            "Epoch 3: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 6s 9ms/step - loss: 0.0018 - val_loss: 6.2321e-04\n",
            "Epoch 4/800\n",
            "656/657 [============================>.] - ETA: 0s - loss: 0.0016\n",
            "Epoch 4: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 4s 6ms/step - loss: 0.0016 - val_loss: 6.9332e-04\n",
            "Epoch 5/800\n",
            "654/657 [============================>.] - ETA: 0s - loss: 0.0017\n",
            "Epoch 5: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0017 - val_loss: 8.7726e-04\n",
            "Epoch 6/800\n",
            "651/657 [============================>.] - ETA: 0s - loss: 0.0014\n",
            "Epoch 6: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0014 - val_loss: 4.7922e-04\n",
            "Epoch 7/800\n",
            "653/657 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 7: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0011 - val_loss: 7.9120e-04\n",
            "Epoch 8/800\n",
            "655/657 [============================>.] - ETA: 0s - loss: 0.0010\n",
            "Epoch 8: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0010 - val_loss: 3.5544e-04\n",
            "Epoch 9/800\n",
            "654/657 [============================>.] - ETA: 0s - loss: 0.0011\n",
            "Epoch 9: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0011 - val_loss: 9.3496e-04\n",
            "Epoch 10/800\n",
            "644/657 [============================>.] - ETA: 0s - loss: 0.0021\n",
            "Epoch 10: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0021 - val_loss: 7.1343e-04\n",
            "Epoch 11/800\n",
            "656/657 [============================>.] - ETA: 0s - loss: 0.0015\n",
            "Epoch 11: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0015 - val_loss: 4.4896e-04\n",
            "Epoch 12/800\n",
            "646/657 [============================>.] - ETA: 0s - loss: 0.0020\n",
            "Epoch 12: val_loss did not improve from 0.00101\n",
            "657/657 [==============================] - 3s 5ms/step - loss: 0.0020 - val_loss: 9.5530e-04\n",
            "Epoch 13/800\n",
            "650/657 [============================>.] - ETA: 0s - loss: 0.0041\n",
            "Epoch 13: val_loss improved from 0.00101 to 0.00171, saving model to ae8_model\n",
            "657/657 [==============================] - 6s 8ms/step - loss: 0.0041 - val_loss: 0.0017\n",
            "Epoch 13: early stopping\n",
            "0.016871396\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9e4b8b5-1155-462a-ebbd-5f93d7e4f16c",
        "id": "w9-S7E1WOWp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 2s 6ms/step - loss: 0.0129 - val_loss: 9.9182e-04\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0028 - val_loss: 8.9402e-04\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0024 - val_loss: 7.0682e-04\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 0.0018\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0022 - val_loss: 6.7238e-04\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0023 - val_loss: 9.1483e-04\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0033 - val_loss: 0.0020\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 6.8813e-04\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 0.0012\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 6.4170e-04\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 6.0104e-04\n",
            "Epoch 12/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 5.9561e-04\n",
            "Epoch 13/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 7.3784e-04\n",
            "Epoch 14/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 6.4644e-04\n",
            "Epoch 15/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0016 - val_loss: 5.6829e-04\n",
            "Epoch 16/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 5.6909e-04\n",
            "Epoch 17/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0016 - val_loss: 6.5205e-04\n",
            "Epoch 18/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 5.3986e-04\n",
            "Epoch 19/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 5.2176e-04\n",
            "Epoch 20/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 5.4045e-04\n",
            "Epoch 21/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 5.0829e-04\n",
            "Epoch 22/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.9257e-04\n",
            "Epoch 23/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 4.7814e-04\n",
            "Epoch 24/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 4.2542e-04\n",
            "Epoch 25/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 5.8523e-04\n",
            "Epoch 26/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 4.2954e-04\n",
            "Epoch 27/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0011 - val_loss: 3.8567e-04\n",
            "Epoch 28/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 5.5192e-04\n",
            "Epoch 29/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 5.7157e-04\n",
            "Epoch 30/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0017 - val_loss: 5.4141e-04\n",
            "Epoch 31/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 4.0016e-04\n",
            "Epoch 32/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0014 - val_loss: 5.1223e-04\n",
            "Epoch 32: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae8_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de10c091-5463-47cb-832c-638527947f31",
        "id": "Us5g-8dPOWp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "219/219 [==============================] - 3s 9ms/step - loss: 0.0074 - val_loss: 6.1849e-04\n",
            "Epoch 2/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0061 - val_loss: 5.8807e-04\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0060 - val_loss: 6.3446e-04\n",
            "Epoch 4/800\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0057 - val_loss: 5.3775e-04\n",
            "Epoch 5/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0057 - val_loss: 5.7173e-04\n",
            "Epoch 6/800\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0054 - val_loss: 5.2130e-04\n",
            "Epoch 7/800\n",
            "219/219 [==============================] - 2s 10ms/step - loss: 0.0054 - val_loss: 0.0018\n",
            "Epoch 8/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0077 - val_loss: 0.0138\n",
            "Epoch 9/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0067 - val_loss: 0.0011\n",
            "Epoch 10/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0051 - val_loss: 9.2100e-04\n",
            "Epoch 11/800\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0041 - val_loss: 7.8754e-04\n",
            "Epoch 11: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "AMX9E_buOWp_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32ee652-3890-48de-b691-6a45f66f4a16",
        "id": "gyaq8LIyOWp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (6585, 115)\n",
            "Detected anomalies: 5.50430504305043%\n",
            "\n",
            "1\n",
            "Shape of data: (45930, 115)\n",
            "Detected anomalies: 99.81460882461994%\n",
            "\n",
            "2\n",
            "Shape of data: (111480, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (125715, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (151879, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (78244, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (54283, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (28579, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27825, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (88816, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "10\n",
            "Shape of data: (103720, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae8_model')\n",
        "\n",
        "def predict(x, threshold=0.016871396, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4b0e179-0533-4783-c574-3c108290a8da",
        "id": "Mbo50abCOWp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (16585, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "1\n",
            "Shape of data: (45930, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (111480, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (125715, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (151879, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (78244, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (54283, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (28579, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27825, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (88816, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (103720, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0c46c0a-5baa-417e-ec54-02b2870c47d1",
        "id": "BijUfF_gOWp_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (6585, 115)\n",
            "Detected anomalies: 10.009225092250922%\n",
            "\n",
            "1\n",
            "Shape of data: (45930, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (111480, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (125715, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (151879, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (78244, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (54283, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (28579, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (27825, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (88816, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "10\n",
            "Shape of data: (103720, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## IOT Device 9: SimpleHome XCS7 1003 WHT Security Camera"
      ],
      "metadata": {
        "id": "8NcgTI2GVA7m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading the dataset"
      ],
      "metadata": {
        "id": "vz7DbO1lVA7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_nbaiot(filename):\n",
        "    return np.genfromtxt(\n",
        "        os.path.join(\"/drive/My Drive/Mini_Project_Dataset/N-Balot_Dataset\", filename),\n",
        "        delimiter=\",\",\n",
        "        skip_header=1\n",
        "    )\n",
        "\n",
        "benign = load_nbaiot(\"9.benign.csv\")\n",
        "X_train = benign[:10000]\n",
        "X_train0 = benign[10000:15000]\n",
        "X_train1 = benign[10000:]\n",
        "X_test0 = benign[15000:]\n",
        "X_test1 = load_nbaiot(\"9.mirai.scan.csv\")\n",
        "X_test2 = load_nbaiot(\"9.mirai.ack.csv\")\n",
        "X_test3 = load_nbaiot(\"9.mirai.syn.csv\")\n",
        "X_test4 = load_nbaiot(\"9.mirai.udp.csv\")\n",
        "X_test5 = load_nbaiot(\"9.mirai.udpplain.csv\")\n",
        "X_test6 = load_nbaiot(\"9.gafgyt.combo.csv\")\n",
        "X_test7 = load_nbaiot(\"9.gafgyt.junk.csv\")\n",
        "X_test8 = load_nbaiot(\"9.gafgyt.scan.csv\")\n",
        "X_test9 = load_nbaiot(\"9.gafgyt.tcp.csv\")\n",
        "X_test10 = load_nbaiot(\"9.gafgyt.udp.csv\")"
      ],
      "metadata": {
        "id": "lV8APXd2VA7w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape, X_train0.shape, X_train1.shape, X_test0.shape, X_test1.shape, X_test2.shape,\n",
        "      X_test3.shape, X_test4.shape, X_test5.shape, X_test6.shape, \n",
        "      X_test7.shape, X_test8.shape, X_test9.shape, X_test10.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df3b91aa-e3e6-4247-ed18-3ce0c7dee249",
        "id": "UCd4QnVrVA7w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 115) (5000, 115) (9528, 115) (4528, 115) (43674, 115) (107187, 115) (122479, 115) (157084, 115) (84436, 115) (59398, 115) (27413, 115) (28572, 115) (98075, 115) (102980, 115)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training the autoencoder"
      ],
      "metadata": {
        "id": "oFFZicTfVA7w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train)\n",
        "checkpoint = ModelCheckpoint(\"ae9_model\", monitor='val_loss', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "ae1 = Autoencoder()\n",
        "ae1.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor,checkpoint]\n",
        ")\n",
        "\n",
        "training_loss = losses.mse(x, ae1(x))\n",
        "threshold = np.mean(training_loss)+np.std(training_loss)\n",
        "print(threshold)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9d7b5cf-d47f-4b5f-a642-0a957a8f9a4a",
        "id": "420oQfjuVA7w"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.0074\n",
            "Epoch 1: val_loss improved from -inf to 0.00386, saving model to ae9_model\n",
            "219/219 [==============================] - 9s 36ms/step - loss: 0.0074 - val_loss: 0.0039\n",
            "Epoch 2/800\n",
            "211/219 [===========================>..] - ETA: 0s - loss: 0.0019\n",
            "Epoch 2: val_loss did not improve from 0.00386\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0033\n",
            "Epoch 3/800\n",
            "219/219 [==============================] - ETA: 0s - loss: 0.0019\n",
            "Epoch 3: val_loss did not improve from 0.00386\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0019 - val_loss: 0.0034\n",
            "Epoch 4/800\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.0025\n",
            "Epoch 4: val_loss improved from 0.00386 to 0.00409, saving model to ae9_model\n",
            "219/219 [==============================] - 6s 28ms/step - loss: 0.0025 - val_loss: 0.0041\n",
            "Epoch 5/800\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.0026\n",
            "Epoch 5: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 2s 9ms/step - loss: 0.0025 - val_loss: 0.0033\n",
            "Epoch 6/800\n",
            "216/219 [============================>.] - ETA: 0s - loss: 0.0018\n",
            "Epoch 6: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 0.0033\n",
            "Epoch 7/800\n",
            "218/219 [============================>.] - ETA: 0s - loss: 0.0015\n",
            "Epoch 7: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 0.0028\n",
            "Epoch 8/800\n",
            "207/219 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 8: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 0.0039\n",
            "Epoch 9/800\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.0013\n",
            "Epoch 9: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0023\n",
            "Epoch 10/800\n",
            "217/219 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 10: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0012 - val_loss: 0.0022\n",
            "Epoch 11/800\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 9.9419e-04\n",
            "Epoch 11: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.8631e-04 - val_loss: 0.0021\n",
            "Epoch 12/800\n",
            "213/219 [============================>.] - ETA: 0s - loss: 0.0012\n",
            "Epoch 12: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0012 - val_loss: 0.0030\n",
            "Epoch 13/800\n",
            "219/219 [==============================] - ETA: 0s - loss: 8.8515e-04\n",
            "Epoch 13: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 8.8515e-04 - val_loss: 0.0022\n",
            "Epoch 14/800\n",
            "212/219 [============================>.] - ETA: 0s - loss: 9.6730e-04\n",
            "Epoch 14: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.6629e-04 - val_loss: 0.0020\n",
            "Epoch 15/800\n",
            "217/219 [============================>.] - ETA: 0s - loss: 7.2965e-04\n",
            "Epoch 15: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 7.2785e-04 - val_loss: 0.0020\n",
            "Epoch 16/800\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 6.9721e-04\n",
            "Epoch 16: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 6.9843e-04 - val_loss: 0.0019\n",
            "Epoch 17/800\n",
            "214/219 [============================>.] - ETA: 0s - loss: 7.9434e-04\n",
            "Epoch 17: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 7.9611e-04 - val_loss: 0.0033\n",
            "Epoch 18/800\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 9.2242e-04\n",
            "Epoch 18: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 9.6337e-04 - val_loss: 0.0034\n",
            "Epoch 19/800\n",
            "209/219 [===========================>..] - ETA: 0s - loss: 0.0013\n",
            "Epoch 19: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 0.0031\n",
            "Epoch 20/800\n",
            "208/219 [===========================>..] - ETA: 0s - loss: 0.0011\n",
            "Epoch 20: val_loss did not improve from 0.00409\n",
            "219/219 [==============================] - 1s 5ms/step - loss: 0.0010 - val_loss: 0.0023\n",
            "Epoch 21/800\n",
            "212/219 [============================>.] - ETA: 0s - loss: 9.3707e-04\n",
            "Epoch 21: val_loss improved from 0.00409 to 0.01693, saving model to ae9_model\n",
            "219/219 [==============================] - 3s 15ms/step - loss: 0.0010 - val_loss: 0.0169\n",
            "Epoch 21: early stopping\n",
            "0.030374795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = MinMaxScaler()\n",
        "x = scaler.fit_transform(X_train0)\n",
        "\n",
        "ae = Autoencoder()\n",
        "ae.compile(optimizer=Adam(learning_rate=0.01), loss='mse')\n",
        "monitor = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=1e-9,\n",
        "    patience=5,\n",
        "    verbose=1,\n",
        "    mode='auto'\n",
        ")\n",
        "ae.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss1 = losses.mse(x, ae(x))\n",
        "threshold1 = np.mean(training_loss1)+np.std(training_loss1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64c319ed-ece5-4e2c-f4f9-70ae3b1ccb89",
        "id": "RDwnD2NeVA7x"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0137 - val_loss: 7.5675e-04\n",
            "Epoch 2/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0034 - val_loss: 2.8901e-04\n",
            "Epoch 3/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0029 - val_loss: 2.2358e-04\n",
            "Epoch 4/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0029 - val_loss: 2.9115e-04\n",
            "Epoch 5/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0027 - val_loss: 2.0110e-04\n",
            "Epoch 6/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0037 - val_loss: 2.3663e-04\n",
            "Epoch 7/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0034 - val_loss: 3.6884e-04\n",
            "Epoch 8/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0031 - val_loss: 2.2629e-04\n",
            "Epoch 9/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 2.0481e-04\n",
            "Epoch 10/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0021 - val_loss: 1.8098e-04\n",
            "Epoch 11/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 1.8019e-04\n",
            "Epoch 12/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 1.9115e-04\n",
            "Epoch 13/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 1.9257e-04\n",
            "Epoch 14/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0021 - val_loss: 1.8194e-04\n",
            "Epoch 15/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0020 - val_loss: 1.8103e-04\n",
            "Epoch 16/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0020 - val_loss: 1.6206e-04\n",
            "Epoch 17/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 1.8095e-04\n",
            "Epoch 18/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0018 - val_loss: 1.5545e-04\n",
            "Epoch 19/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 3.0154e-04\n",
            "Epoch 20/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0017 - val_loss: 1.4193e-04\n",
            "Epoch 21/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0019 - val_loss: 1.5818e-04\n",
            "Epoch 22/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0018 - val_loss: 1.3682e-04\n",
            "Epoch 23/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 1.7493e-04\n",
            "Epoch 24/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 1.3842e-04\n",
            "Epoch 25/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0015 - val_loss: 2.0543e-04\n",
            "Epoch 26/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 2.3749e-04\n",
            "Epoch 27/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0023 - val_loss: 3.8080e-04\n",
            "Epoch 27: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af1 = load_model('ae9_model')\n",
        "\n",
        "af1.fit(\n",
        "    x=x,\n",
        "    y=x,\n",
        "    epochs=800,\n",
        "    validation_split=0.3,\n",
        "    shuffle=True,\n",
        "    callbacks=[monitor]\n",
        ")\n",
        "\n",
        "training_loss2 = losses.mse(x, af1(x))\n",
        "threshold2 = np.mean(training_loss2)+np.std(training_loss2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcd467f2-6df9-4af5-fb0c-0f95b881791d",
        "id": "T0J2nqGrVA7x"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/800\n",
            "110/110 [==============================] - 2s 7ms/step - loss: 0.0025 - val_loss: 1.1948e-04\n",
            "Epoch 2/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0019 - val_loss: 1.9171e-04\n",
            "Epoch 3/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0015 - val_loss: 1.1496e-04\n",
            "Epoch 4/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0014 - val_loss: 1.1875e-04\n",
            "Epoch 5/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 1.1745e-04\n",
            "Epoch 6/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 3.3758e-04\n",
            "Epoch 7/800\n",
            "110/110 [==============================] - 1s 6ms/step - loss: 0.0013 - val_loss: 1.2081e-04\n",
            "Epoch 8/800\n",
            "110/110 [==============================] - 1s 5ms/step - loss: 0.0013 - val_loss: 1.2749e-04\n",
            "Epoch 8: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Testing the autoencoder"
      ],
      "metadata": {
        "id": "BCNARAtkVA7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold1, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, ae(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1285e616-1869-46ec-d5f0-c6100e9e84c2",
        "id": "nYPOfDlEVA7x"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (4528, 115)\n",
            "Detected anomalies: 3.080728581065887%\n",
            "\n",
            "1\n",
            "Shape of data: (43674, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (107187, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (122479, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (157084, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (84436, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (59398, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (27413, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (28572, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (98075, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "10\n",
            "Shape of data: (102980, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "af = load_model('ae9_model')\n",
        "\n",
        "def predict(x, threshold=0.030374795, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_train1, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9018e6f-f273-4cc6-9961-2820e6fbfdde",
        "id": "rSoaShn9VA7x"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (9528, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "1\n",
            "Shape of data: (43674, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (107187, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (122479, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (157084, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (84436, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (59398, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (27413, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (28572, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (98075, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "10\n",
            "Shape of data: (102980, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(x, threshold=threshold2, window_size=82):\n",
        "    x = scaler.transform(x)\n",
        "    predictions = losses.mse(x, af1(x)) > threshold\n",
        "    # Majority voting over `window_size` predictions\n",
        "    return np.array([np.mean(predictions[i-window_size:i]) > 0.5\n",
        "                     for i in range(window_size, len(predictions)+1)])\n",
        "\n",
        "test_data = [X_test0, X_test1, X_test2, X_test3, X_test4, X_test5, X_test6, X_test7, X_test8, X_test9, X_test10]\n",
        "\n",
        "for i, x in enumerate(test_data):\n",
        "    print(i)\n",
        "    outcome = predict(x)\n",
        "    print_stats(x, outcome)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4f7b937a-8d4f-40a0-9007-64de02670cdd",
        "id": "LMViAp2dVA7x"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "Shape of data: (4528, 115)\n",
            "Detected anomalies: 3.1481897908702496%\n",
            "\n",
            "1\n",
            "Shape of data: (43674, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "2\n",
            "Shape of data: (107187, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "3\n",
            "Shape of data: (122479, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "4\n",
            "Shape of data: (157084, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "5\n",
            "Shape of data: (84436, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "6\n",
            "Shape of data: (59398, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "7\n",
            "Shape of data: (27413, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "8\n",
            "Shape of data: (28572, 115)\n",
            "Detected anomalies: 100.0%\n",
            "\n",
            "9\n",
            "Shape of data: (98075, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n",
            "10\n",
            "Shape of data: (102980, 115)\n",
            "Detected anomalies: 0.0%\n",
            "\n"
          ]
        }
      ]
    }
  ]
}